# Project- Segment Anything Model Finetuning for Remote Sensing Applications
## Name- Aileen Ni
### Milestone 1- Dockerfile (Creates a docker image of program) I moved the files to the MileStone1 Directory, so the date changed may not reflect the actual due date of Milestone 1
### Milestone 2- Using google colab, I replicated the workflow for the SAM model used by the author. File is in Milestone2 directory
### MileStone 3- required libraraies are posted in requirements.txt under milestone 1
#### Recreate the data, numpy arrays, and dataset from Training.py, by downloading the parquet file training data and running each section. Because the npy files, and finished model and the dataset file cost over 100MB to upload, the model could not be commited. Pictures are shown in the results folder, form the val dataset, by first using the bounding box as our input tensor vs a grid of points.
#### Results: Because of the high amount of data, my computer doesn't have enough GPU to train over it, so the data had to be cut. The resulting training speed took over 70 hours in total for 10 batches. The model is saved at every batch checkpoint, and each model has around the size of 366 MB, hence it's too large to be updated onto github.
##### The model's performance is moderately adequate when it comes down to a grid as a tensor input, grid_size=5, with no bounding box supplied by the label. The model correctly defined most of the sidewalks, but also strayed away from the sidewalks to other parts of the picture. However, the model did sigificantly good when bounding boxes are provided as input tensor. The results are suppiled in the results directory, with the grid points tensor corresponding to "valresult_grid.png".